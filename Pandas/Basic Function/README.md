# Basic Functionality  

판다스에서 중요하게 사용되는 기능들에 대해 알아본다. 일단 기능들을 사용하기위해 인덱스, 시리즈, 데이터프레임을 생성한다.  

```Python  
# 인덱스 생성(시계열)
>>> t_idx = pd.date_range('2020-01-01', periods=8, freq='M')  
>>> t_idx  
```

```
DatetimeIndex(['2020-01-31', '2020-02-29', '2020-03-31', '2020-04-30',   
               '2020-05-31', '2020-06-30', '2020-07-31', '2020-08-31'],   
              dtype='datetime64[ns]', freq='M')   
```

```Python  
# 시리즈 생성
>>> s = pd.Series(np.random.randn(8),index = t_idx)   
>>> s  
```

```
2020-01-31   -0.947804  
2020-02-29    0.621019  
2020-03-31    0.526869  
2020-04-30    1.208103  
2020-05-31   -0.112500  
2020-06-30   -0.739076  
2020-07-31    1.419800  
2020-08-31   -2.781923  
Freq: M, dtype: float64  
```  

```Python
# 데이터프레임 생성
>>> df = pd.DataFrame({'One' : [1,2,3,4,5,6,7,8], 'Two' : [8,7,6,5,4,3,2,1,]}, index=t_idx)  
>>> df  
```  

 | | One | Two  
 |-|:---:|:---:  
 2020-01-31 | 1 | 8  
 2020-02-29 | 2 | 7  
 2020-03-31 | 3 | 6  
 2020-04-30 | 4 | 5  
 2020-05-31 | 5 | 4  
 2020-06-30 | 6 | 3  
 2020-07-31 | 7 | 2  
 2020-08-31 | 8 | 1  


## 1.Head & Tail  

시리즈나 데이터프레임의 특정 일부분만 보고자한다면 **head** 나 **tail** 메소드를 사용한다. 괄호안에 숫자를 입력하면 그 범위만큼의 값이 나타나며 기본값은 **5** 이다.  

```Python
# 상위 5개
>>> s.head()
```  

```
2020-01-31   -0.947804  
2020-02-29    0.621019  
2020-03-31    0.526869  
2020-04-30    1.208103  
2020-05-31   -0.112500  
Freq: M, dtype: float64  
```  

```Python  
# 하위 5개  
>>> s.tail(6)
```  

```
2020-03-31    0.526869  
2020-04-30    1.208103  
2020-05-31   -0.112500  
2020-06-30   -0.739076  
2020-07-31    1.419800  
2020-08-31   -2.781923  
Freq: M, dtype: float64  
```  

## 2.Attribute and underlying data  

판다스의 객체(인덱스, 시리즈, 데이터프레임)들은 **shape** 메소드를 사용하여 객체가 가지고있는 축의 차원을 ndarray로 반환하여 보여준다.  

```Python  
# 시리즈 shape
>>> s.shape
```

```
(8,)
```

```Python  
# 데이터프레임 shape
>>> df.shape  
```

```
(8, 2)
```  

```Python  
# 인덱스 shape
>>> t_idx.shape
```  

```
(8,)
```  

판다스는 넘파이 모듈로 구성되어있기 때문에 **슬라이싱(Slicing)** 을 통한 검색이 가능하다.  

```Python  
# 0~3번째의 행을 출력
>>> df[:3]
```

 | | One | Two  
 |-|:---:|:---:  
2020-01-31 | 1 | 8  
2020-02-29 | 2 | 7  
2020-03-31 | 3 | 6  

```Python  
# 2~5번째의 행을 출력
>>> df[2:5]
```  

 | | One | Two  
 |-|:---:|:---:  
2020-03-31 | 3 | 6  
2020-04-30 | 4 | 5  
2020-05-31 | 5 | 4  

판다스의 객체는 **배열(array)** 로 구성되어 값들을 저장하고 있다. 시리즈나 인덱스에서 **array** 속성을 사용하여 내부 데이터와 자료형을 확인할 수 있다.  

```Python  
# 시리즈 내부의 값
>>> s.array
```  

```
<PandasArray>
[ -0.9478040550309271,   0.6210189401447063,   0.5268690969841191,  
   1.2081027538889946, -0.11250048407157869,  -0.7390759558578995,  
   1.4198001438584995,   -2.781922728141299]  
Length: 8, dtype: float64  
```  

```Python  
# 시리즈 인덱스 값(시계열)
>>> s.index.array
```  

```
<DatetimeArray>
['2020-01-31 00:00:00', '2020-02-29 00:00:00', '2020-03-31 00:00:00',  
 '2020-04-30 00:00:00', '2020-05-31 00:00:00', '2020-06-30 00:00:00',  
 '2020-07-31 00:00:00', '2020-08-31 00:00:00']  
Length: 8, dtype: datetime64[ns]  
```  

만약 배열을 넘파이 배열로 확인해야 한다면 **to_numpy** 나 **numpy.asarray** 메소드를 사용한다.  

```Python  
# to_numpy 메소드 사용
>>> s.to_numpy()
```  

```
array([-0.94780406,  0.62101894,  0.5268691 ,  1.20810275, -0.11250048,  
       -0.73907596,  1.41980014, -2.78192273])   
```  

```Python  
# np.asarray 메소드 사용
>>> np.asarray(s)
```  

```
array([-0.94780406,  0.62101894,  0.5268691 ,  1.20810275, -0.11250048,  
       -0.73907596,  1.41980014, -2.78192273])  
```  

to_numpy 메소드는 결과로 반환되는 ndarray의 자료형을 제어한다. 예를들어 타임존이 설정되어있는 시계열 데이터를 메소드를 사용하여 ndarray로 반환한다면, 넘파이는 타임존을 나타내는 방법을 가지고있지 않다. 그렇기때문에 2가지 경우를 사용할 수 있다.  

1. ndarray의 자료형을 **Object** 로 지정하면 반환되는 ndarray에 **tz** 로 타임존의 정보가 나타난다.  
2. ndarray의 자료형을 **datetime64[ns]** 로 지정하면 시간정보가 UTC로 변환되고 타임존은 버린다.  

```Python  
# 타임존을 설정한 시계열 시리즈 생성
>>> t_s = pd.Series(pd.date_range('2020', periods=2, tz='CET'))  
>>> t_s  
```  

```
0   2020-01-01 00:00:00+01:00  
1   2020-01-02 00:00:00+01:00  
dtype: datetime64[ns, CET]  
```  

```Python  
# 자료형 Object  
>>> t_s.to_numpy(dtype=object)  
```  

```
array([Timestamp('2020-01-01 00:00:00+0100', tz='CET', freq='D'),  
       Timestamp('2020-01-02 00:00:00+0100', tz='CET', freq='D')],   
      dtype=object)  
```  

```Python  
# 자료형 datetime64[ns]
>>> t_s.to_numpy(dtype='datetime64[ns]')
```  

```
array(['2019-12-31T23:00:00.000000000', '2020-01-01T23:00:00.000000000'],   
      dtype='datetime64[ns]')  
```  

데이터프레임의 경우 내부 데이터들이 모두 같은 자료형을 가지고 있다면 to_numpy 메소드를 사용한 뒤의 반환결과도 같은 자료형을 가지게 된다. 그러나 만약 내부 자료형이 다른 경우에는 조건에 따라 자료형이 달라진다.
> 만약 문자형이 하나라도 있으면 반환결과의 자료형은 문자형(object)가 되며, 내부값들이 정수와 소수로 구성되어 있으면 반환결과의 자료형은 소수(float64)가 된다.  

```Python  
# 정수, 소수, 문자형이 섞여있는 데이터프레임 생성
>>> df2 = pd.DataFrame({'A' : [1,2,np.nan,'a'], 'B' : [3,4,5,6]})  
>>> df2
```   

 | | A | B  
 |-|:-:|:-:  
0 | 1 | 3  
1 | 2 | 4  
2 | NaN | 5  
3 | a | 6  

```Python  
>>> df2.to_numpy()
```  

```
array([[1, 3],  
       [2, 4],  
       [nan, 5],  
       ['a', 6]], dtype=object)   
```  

```Python  
# 정수와 누락값(소수)으로 구성되어 있는 데이터프레임 생성
>>> df3 = pd.DataFrame({'A' : [1,2,np.nan,3], 'B' : [4,5,6,7]})   
>>> df3
```  

 | | A | B  
 |-|:-:|:-:  
0 | 1.0 | 4  
1 | 2.0 | 5  
2 | NaN | 6  
3 | 3.0 | 7  

```Python  
>>> df3.to_numpy()
```  

```
array([[ 1.,  4.],  
       [ 2.,  5.],  
       [nan,  6.],  
       [ 3.,  7.]])  
```  

## 3.Accelerated operations  

판다스는 **numexpr** 라이브러리와 **bottleneck** 라이브러리를 사용하여 이진 숫자와 불리언 연산의 처리 속도를 가속화할 수 있다. 이 라이브러리들은 특히 큰 데이터 셋을 다룰때 유용하다. 특히 bottleneck은 NaN이 있는 배열을 다룰때 유용하다.  

```Python  
>>> import bottleneck as bn  
>>> import time  
```  

```Python  
# bottleneck 라이브러리 사용   
>>> start = time.time() # 시작시간 측정  
>>> print(bn.nanmean(df['home_goals']), time.time() - start)
```  

```  
1.5517993456924755 0.0002181529998779297
```  

```Python  
# 넘파이 모듈 사용  
start = time.time() # 시작시간 측정
print(np.nanmean(df['home_goals']), time.time() - start)
```  

```  
1.5517993456924755 0.00026988983154296875
```

## 4. Flexible binary operations  

판다스에서 두 데이터프레임간의 연산을 수행하게 되면 두 가지에 중점을 두게된다.  

```
1. 고차원 혹은 저차원의 데이터프레임간 브로드캐스팅  
2. 누락값의 계산
```  

이런 문제를 관리하는 방법들을 아래에 설명한다.  

### Matching / broadcasting behavior  

데이터프레임은 이항 연산을 수행하기 위해 **add(), sub(), mul(), div(), radd(), rsub()** 메소드를 지원한다.  

이 메소드들을 사용하고자 할 땐 행이나 열의 축을 기준으로 잡아야한다.  

```Python  
>>> df = pd.DataFrame({'One' : pd.Series(np.random.randn(4), index=['a','b','c','d']),
                    'Two' : pd.Series(np.random.randn(3), index=['a','c','d']),
                   'Three' : pd.Series(np.random.randn(3), index=['b','c','d'])})  

>>> df
```  

 | | One | Two | Three  
 |-|:---:|:---:|:-----:  
a | 1.008765 | -0.175352 | NaN  
b | 1.748897 | NaN | 0.624603  
c | 1.078679 | -0.866894 | -0.950405  
d | -1.573860 | 0.170444 | 0.322723  

```Python  
# 연산을 할 시리즈 생성(데이터프레임에서 한 행을 추출)
>>> row = df.iloc[1]  
>>> row
```  

```  
One      1.748897  
Two           NaN  
Three    0.624603  
Name: b, dtype: float64
```  

```Python  
>>> df.sub(row, axis='columns')
```  

| | One | Two | Three  
|-|:---:|:---:|:-----:  
a | -0.740132 | NaN | NaN  
b | 0.000000 | NaN | 0.000000  
c | -0.670218 | NaN | -1.575008  
d | -3.322757 | NaN | -0.301881  

```Python  
>>> df.sub(row, axis=1)
```  

| | One | Two | Three  
|-|:---:|:---:|:-----:  
a | -0.740132 | NaN | NaN  
b | 0.000000 | NaN | 0.000000  
c | -0.670218 | NaN | -1.575008  
d | -3.322757 | NaN | -0.301881  

```Python  
# 연산을 할 시리즈 생성(데이터프레임에서 한 열을 추출)
>>> column = df['One']  
>>> column
```  

```
a    1.008765  
b    1.748897  
c    1.078679  
d   -1.573860  
Name: One, dtype: float64
```

```Python  
>>> df.sub(column, axis=0)
```  

| | One | Two | Three  
|-|:---:|:---:|:-----:  
a | 0.0 | -1.184117 | NaN  
b | 0.0 | NaN | -1.124294  
c | 0.0 | -1.945573 | -2.029084  
d | 0.0 | 1.744304 | 1.896582  

```Python  
>>> df.sub(column, axis='index')
```  

| | One | Two | Three  
|-|:---:|:---:|:-----:  
a | 0.0 | -1.184117 | NaN  
b | 0.0 | NaN | -1.124294  
c | 0.0 | -1.945573 | -2.029084  
d | 0.0 | 1.744304 | 1.896582  

멀티인덱스를 가지는 데이터프레임과 시리즈의 연산또한 가능하다.  

```Python  
# 데이터프레임 사본 생성
>>> m_df = df.copy()  
# 멀티인덱스 생성  
>> m_df.index = pd.MultiIndex.from_tuples([(1,'a'),(1,'b'),(1,'c'),(2,'a')], names=['first','second'])
>>> m_df
```  

<img width="304" alt="1" src="https://user-images.githubusercontent.com/43739827/76315244-a911bc00-631b-11ea-9277-7805774509d7.png"></img>  

```Python  
>>> m_df.sub(column, axis=0, level='second')
```

<img width="308" alt="2" src="https://user-images.githubusercontent.com/43739827/76315278-b75fd800-631b-11ea-8ce7-b605a39a1147.png"></img>

**divmod()** 메소드를 사용하여 데이터의 나누기 연산을 했을때의 데이터를 구할 수 있다.  

```Python  
# 0~10까지의 정수를 원소로하는 시리즈 생성
>>> s = pd.Series(np.arange(10))  
>>> s
```  

```
0    0  
1    1  
2    2  
3    3  
4    4  
5    5  
6    6  
7    7  
8    8  
9    9  
dtype: int64
```  

```Python  
>>> div, rem = divmod(s, 3)
```  

```Python
# s를 3으로 나눈 몫
>>> div
```  

```
0    0  
1    0  
2    0  
3    1  
4    1  
5    1  
6    2  
7    2  
8    2  
9    3  
dtype: int64  
```  

```Python
# s를 3으로 나눈 나머지  
>>> rem
```  

```  
0    0  
1    1  
2    2  
3    0  
4    1  
5    2  
6    0  
7    1  
8    2  
9    0   
dtype: int64
```  

특정값들을 요소로 가지는 리스트의 divmod 연산또한 가능하다.  

```Python  
# 리스트를 지정
>>> div, rem = divmod(s, [2,2,2,3,3,3,4,4,4,5])
```  

```Python
# 리스트로 시리즈를 나눈 몫  
>>> div
```  

```
0    0  
1    0  
2    1  
3    1  
4    1  
5    1  
6    1  
7    1  
8    2  
9    1  
dtype: int64
```  

```Python
# 리스트로 시리즈를 나눈 몫  
>>> rem
```  

```
0    0  
1    1  
2    0  
3    0  
4    1  
5    2  
6    2  
7    3  
8    0  
9    4  
dtype: int64
```  

### Missing data / operations will fill values

시리즈와 데이터프레임에서 산술연산을 할 때 둘 중 하나의 요소가 NaN이라면 **fill_value** 매개변수를 이용해 NaN의 값을 특정값으로 대체시킬 수 있다. 그러나 양쪽 객체의 같은 위치에 두 요소가 모두 NaN값이라면 특정값으로 채워지지 않는다.  

```Python
>>> df = pd.DataFrame({'One' : {'a': 1.394981, 'b' : 0.343054, 'c' : 0.695246},
                  'Two' : {'a' : 1.772517, 'b' : 1.912123, 'c' : 1.478369, 'd' : 0.279344},
                  'Three' : {'b' : -0.050390, 'c' : 1.227435, 'd' : -0.613172}})  
>>> df
```  

|    |        One |      Two |      Three |
|:---|-----------:|---------:|-----------:|
| a  |   1.39498  | 1.77252  | nan        |
| b  |   0.343054 | 1.91212  |  -0.05039  |
| c  |   0.695246 | 1.47837  |   1.22744  |
| d  | nan        | 0.279344 |  -0.613172 |  

```Python  
>>> df2 = pd.DataFrame({'One' : {'a' : 1.394981, 'b' : 0.343054, 'c' : 0.695246},
                   'Two' : {'a' : 1.772517, 'b' : 1.912123, 'c' : 1.478369, 'd' : 0.279344},
                   'Three' : {'a' : 1.000000 , 'b' : -0.050390, 'c' : 1.227435, 'd' : -0.613172}})  
>>> df2
```  

|    |        One |      Two |     Three |
|:---|-----------:|---------:|----------:|
| a  |   1.39498  | 1.77252  |  1        |
| b  |   0.343054 | 1.91212  | -0.05039  |
| c  |   0.695246 | 1.47837  |  1.22744  |
| d  | nan        | 0.279344 | -0.613172 |  

```Python  
>>> df + df2
```  

|    |        One |      Two |     Three |
|:---|-----------:|---------:|----------:|
| a  |   2.78996  | 3.54503  | nan       |
| b  |   0.686108 | 3.82425  |  -0.10078 |
| c  |   1.39049  | 2.95674  |   2.45487 |
| d  | nan        | 0.558688 |  -1.22634 |  

```Python  
>>> df.add(df2, fill_value=0)
```  

|    |        One |      Two |    Three |
|:---|-----------:|---------:|---------:|
| a  |   2.78996  | 3.54503  |  1       |
| b  |   0.686108 | 3.82425  | -0.10078 |
| c  |   1.39049  | 2.95674  |  2.45487 |
| d  | nan        | 0.558688 | -1.22634 |

```Python  
>>> df.add(df2, fill_value=1)  
```  

|    |        One |      Two |    Three |
|:---|-----------:|---------:|---------:|
| a  |   2.78996  | 3.54503  |  2       |
| b  |   0.686108 | 3.82425  | -0.10078 |
| c  |   1.39049  | 2.95674  |  2.45487 |
| d  | nan        | 0.558688 | -1.22634 |  

### Flexible comparisons  

시리즈와 데이터프레임은 비교 연산을 수행하는 메소드 **eq, ne, lt, gt, le, ge** 를 지원한다.  

```Python
>>> df.eq(df2)
```  

|    |   One |   Two |   Three |
|:---|------:|------:|--------:|
| a  |  True |  True |    Flase|
| b  |  True |  True |    True |
| c  |  True |  True |    True |
| d  |  Flase|  True |    True |  

```Python  
>>> df.ne(df2)
```  

|    |   One |   Two |   Three |
|:---|------:|------:|--------:|
| a  |  Flase|  Flase|    True |
| b  |  Flase|  Flase|   Flase |
| c  |  Flase|  Flase|   Flase |
| d  |  True |  Flase|   Flase |  

```Python  
>>> df.lt(df2)
```  

|    |   One |   Two |   Three |
|:---|------:|------:|--------:|
| a  |  Flase|  Flase|    Flase|
| b  |  Flase|  Flase|    Flase|
| c  |  Flase|  Flase|    Flase|
| d  |  Flase|  Flase|    Flase|

```  
eq : 객체의 요소끼리가 같으면 True, 다르면 False를 반환한다. 만약 비교하는 요소가 모두 누락값이라면 False를 반환한다.  
ne : eq의 반대개념으로 같으면 False, 다르면 True를 반환한다. 만약 비교하는 요소가 모두 누락값이라면 True를 반환한다.  
lt : less than의 약어로 기준이 되는 요소의 값이 적으면 True, 크거나 같으면 False를 반환한다.  
gt : greater than의 약어로 기준이 되는 요소의 값이 크면 True, 작거나 같으면 False를 반환한다.  
le : less than or equal의 약어로 기준이 되는 요소의 값이 적거나 같으면 True, 크면 False를 반환한다.  
ge : greater than or equal의 약어로 기준이 되는 요소의 값이 크거나 같으면 True, 작으면 False를 반환한다.  
```  

결과의 반환값이 boolean인것을 확인할 수 있다.  

### Boolean reductions  

불리언 결과를 간략하게 보여주는 메소드로 **empty, any(), all(), bool()** 을 제공한다.  

```Python  
>>> (df > 0).all()
```  

```
One      False   
Two       True  
Three    False  
dtype: bool  
```  

```Python  
>>> (df > 0).any()
```  

```
One      True  
Two      True  
Three    True  
dtype: bool  
```  

최종 불리언 값만을 도출할 수 있다.  

```Python  
>>> (df > 0).any().any()
```  

```  
True
```  

판다스 객체가 비어있음을 확인하고 싶으면 **empty** 객체를 사용한다.  

```Python  
>>> df.empty
```  

```  
False
```  

```Python  
>>> pd.DataFrame(columns=list('ABC')).empty
```  

```  
True
```  

판다스의 객체가 불리언 요소를 가지는지 확인하고 싶다면 **bool()** 메소드를 사용한다.  

```Python  
>>> bool(df.iloc[0][0])
```  

```
True
```   

### Comparing if objects are equivalent  

종종 같은 결과를 반환하는 다른 연산을 확인할 수 있다. 예를들어 **df + df** 와 **df * 2** 의 결과는 같다. 그러나 False와 False의 ==연산은 False를 반환하기 때문에 단순한 ==연산으로는 객체의 요소가 같은지 정확하게 확인할 수 없다.  

```Python  
# False 끼리의 논리연산은 False를 반환한다.
>>> df + df == df * 2
```  

|    |   One |   Two |   Three |
|:---|------:|------:|--------:|
| a  |   True|   True|    False|
| b  |   True|   True|     True|
| c  |   True|   True|     True|
| d  |  False|   True|     True|  

**equals()** 메소드를 사용하면 비교하는 대상의 객체들이 같은지를 확인할 수 있다.  

```Python  
>>> (df + df).equals(df * 2)
```  

```  
True
```  

### Comparing array-like objects  

판다스는 리스트를 이용한 간단한 논리연산이 가능하다.  

```Python  
>>> pd.Series(['One', 'Two', 'Three']) == 'Two'  
```  

```
0    False  
1     True  
2    False  
dtype: bool  
```  

```Python  
>>> pd.Index(['Four', 'Five', 'Six']) == 'Five'
```  

```  
array([False,  True, False])
```  

시리즈와 인덱스끼리의 논리연산이 가능하며 이때 각 객체의 길이는 같아야만 한다.  

```Python
>>> pd.Series(['One', 'Two', 'Three']) == pd.Index(['One', 'Five', 'Six'])
```  

```  
0     True  
1    False  
2    False  
dtype: bool  
```  

```Python  
>>> pd.Series(['One', 'Two', 'Three']) == pd.Series(['One', 'Two'])
```  

```  
0     True  
1    False  
2    False  
dtype: bool  
```  

넘파이와의 차이점은 넘파이는 브로드캐스팅이 된다는것이다.  

```Python  
>>> np.array([1,2,3]) == np.array([1])
```  

```
array([ True, False, False])
```  

### Combining overlapping data sets  

두 개의 비슷한 데이터셋을 합칠때 **combine_first()** 메소드를 사용하여 기준이 되는 데이터셋의 누락값이나 가지지 않은 인덱스를 추가할 수 있다.  

```Python  
>>> df1 = pd.DataFrame({'A' : [1., np.nan, 3., 5., np.nan],
                   'B' : [np.nan, 2., 3., np.nan, 6.]})
```  

|    |   A |   B |
|---:|----:|----:|
|  0 |   1 | nan |
|  1 | nan |   2 |
|  2 |   3 |   3 |
|  3 |   5 | nan |
|  4 | nan |   6 |  

```Python  
>>> df2 = pd.DataFrame({'A' : [5., 2., 4., np.nan, 3., 7.],
                   'B' : [np.nan, np.nan, 3., 4., 6., 8.]})
```  

|    |   A |   B |
|---:|----:|----:|
|  0 |   5 | nan |
|  1 |   2 | nan |
|  2 |   4 |   3 |
|  3 | nan |   4 |
|  4 |   3 |   6 |
|  5 |   7 |   8 |  

```Python  
>>> df1.combine_first(df2)
```  

|    |   A |   B |
|---:|----:|----:|
|  0 |   1 | nan |
|  1 |   2 |   2 |
|  2 |   3 |   3 |
|  3 |   5 |   4 |
|  4 |   3 |   6 |
|  5 |   7 |   8 |  

```Python  
>>> df2.combine_first(df1)
```  

|    |   A |   B |
|---:|----:|----:|
|  0 |   5 | nan |
|  1 |   2 |   2 |
|  2 |   4 |   3 |
|  3 |   5 |   4 |
|  4 |   3 |   6 |
|  5 |   7 |   8 |  

## 5.Descriptive statistics  

**기술 통계학(Descriptive statistics)** 을 계산하기 위한 판다스만의 메소드가 존재한다.  

```  
* Series : axis를 지정하지 않는다.  
* DataFrame : 인덱스설정(axis=0)<- 기본값, 컬럼설정(axis=1)
```  

Function | Description  
:-------:|:-----------:  
count | 누락값을 포함하지 않은 요소들의 갯수  
sum | 값들의 합  
mean | 값들의 평균  
mad | 평균절대편차  
median | 값들의 중앙값(median)  
min | 최솟값  
max | 최댓값  
mode | 최빈값(가장 많이 관측되는 수)  
abs | 절댓값  
prod | 값들의 곱  
std | 표준편차의 베셀 보정  
var | 분산  
sem | 표준 오차  
skew | 표본 비대칭도  
kurt | 표본 첨도(kutrosis)  
quantile | 표본 분위수  
cumsum | 누적합(Cumulative sum)
cumprod | 누적곱(Cumulative product)  
cummax | 누적 최댓값  
cummin | 누적 최솟값


```Python  
>>> df
```  

|    |        One |      Two |      Three |
|:---|-----------:|---------:|-----------:|
| a  |   1.39498  | 1.77252  | nan        |
| b  |   0.343054 | 1.91212  |  -0.05039  |
| c  |   0.695246 | 1.47837  |   1.22744  |
| d  | nan        | 0.279344 |  -0.613172 |  

```Python  
>>> df.mean(0)
```  

```  
One      0.811094  
Two      1.360588  
Three    0.187958  
dtype: float64  
```  

```Python  
>>> df.mean(1)
```  

```  
a    1.583749  
b    0.734929  
c    1.133683  
d   -0.166914  
dtype: float64  
```  

여기서 사용되는 모든 메소드는 **skipna** 를 매개변수로 가진다. 이 메소드는 누락값을 확인하는 기능을 하며 기본값은 **True** 이다.  

```Python  
>>> df.sum(0, skipna=False)
```  

```  
One           NaN  
Two      5.442353  
Three         NaN  
dtype: float64  
```  

```Python  
>>> df.sum(axis=1, skipna=True)
```  

```  
a    3.167498  
b    2.204787  
c    3.401050  
d   -0.333828  
dtype: float64  
```  

통계적 계산또한 가능하다. **std()** 메소드는 표준 편차를 구하기위해 사용하는 메소드다.

```Python  
>>> ts_stand = (df - df.mean(0)) / df.std()  
>>> ts_stand.std()
```  

```
One      1.0  
Two      1.0  
Three    1.0  
dtype: float64  
```  

```Python  
>>> xs_stand = df.sub(df.mean(1), axis=0).div(df.std(1), axis=0)  
>>> xs_stand
```  

|    |        One |      Two |      Three |
|:---|-----------:|---------:|-----------:|
| a  |  -0.707107 | 0.707107 | nan        |
| b  |  -0.377425 | 1.13379  |  -0.756361 |
| c  |  -1.09639  | 0.86195  |   0.234443 |
| d  | nan        | 0.707107 |  -0.707107 |  

```Python  
>>> xs_stand.std(1)
```  

```  
a    1.0  
b    1.0  
c    1.0  
d    1.0  
dtype: float64  
```  

**cumsum()** 과 **comprod()** 메소드는 누락값의 위치를 보존한다.  

```Python  
>>> df.cumsum()
```  

|    |       One |     Two |      Three |
|:---|----------:|--------:|-----------:|
| a  |   1.39498 | 1.77252 | nan        |
| b  |   1.73803 | 3.68464 |  -0.05039  |
| c  |   2.43328 | 5.16301 |   1.17705  |
| d  | nan       | 5.44235 |   0.563873 |  

넘파이 모듈을 사용해 데이터프레임의 평균을 구할 수 있다.  

```Python  
>>> np.mean(df['One'])
```  

```  
0.8110936666666667
```  

**Series.nunique()** 메소드는 시리즈에서 누락값을 제외한 유일값의 개수를 반환한다.  

```Python
>>> Series = pd.Series(np.random.randn(500))  
>>> Series[20:200] = np.nan  
>>> Series[10:20] = 5  
>>> Series.nunique()
```  

```  
311
```  

### Summarizing data: describe  

**describe()** 메소드를 사용하면 간략한 통계적 정보를 얻을 수 있다.  

```Python  
>>> series = pd.Series(np.random.randn(1000))  
>>> series[::2] = np.nan  
>>> series.describe()
```  

```  
count    500.000000  
mean      -0.104046  
std        0.973392  
min       -3.459899  
25%       -0.705669  
50%       -0.057655  
75%        0.559557  
max        3.115283  
dtype: float64  
```  

```Python  
>>> df = pd.DataFrame(np.random.randn(1000,5), columns=['a','b','c','d','e'])  
>>> df.iloc[::2] = np.nan  
>>> df.describe()
```  

|       |           a |           b |           c |           d |           e |
|:------|------------:|------------:|------------:|------------:|------------:|
| count | 500         | 500         | 500         | 500         | 500         |
| mean  |  -0.0098391 |  -0.0217725 |  -0.0133153 |   0.0329154 |   0.0208793 |
| std   |   1.04484   |   1.02411   |   1.03689   |   0.991465  |   1.01293   |
| min   |  -3.15347   |  -2.56002   |  -2.98677   |  -2.66778   |  -2.99676   |
| 25%   |  -0.736796  |  -0.682348  |  -0.716998  |  -0.616957  |  -0.754231  |
| 50%   |   0.0153571 |  -0.124131  |  -0.0624372 |   0.0335433 |   0.0098666 |
| 75%   |   0.683469  |   0.678965  |   0.686431  |   0.705677  |   0.736733  |
| max   |   3.26103   |   3.05544   |   3.11557   |   3.24525   |   2.79697   |  

describe 메소드에 매개변수로 **percentiles** 를 사용하면 나타낼 백분율을 설정할 수 있다.  

```Python  
>>> series.describe(percentiles=[.05, .25, .75, .95])
```  

```  
count    500.000000  
mean      -0.104046  
std        0.973392  
min       -3.459899  
5%        -1.804095  
25%       -0.705669  
50%       -0.057655  
75%        0.559557  
95%        1.402325  
max        3.115283  
dtype: float64  
```  

숫자형이 아닌 시리즈객체애 describe 메소드를 사용하면 유일값의 갯수나 가장 빈번하게 발생하는 값의 갯수를 출력한다.  

```Python  
>>> s = pd.Series(['a','a','a','b','b',np.nan,'c','d','a'])  
>>> s.describe()
```  

```  
count     8  
unique    4  
top       a  
freq      4  
dtype: object  
```  

여러 자료형이 섞인 데이터프레임에 describe 메소드를 사용하면 숫자값을 포함하고있는 열만의 정보를 출력한다.  

```Python  
>>> df = pd.DataFrame({'a' : ['Yes','Yes','No','No'], 'b' : range(4)})  
>>> df.describe()
```  

|       |       b |
|:------|--------:|
| count | 4       |
| mean  | 1.5     |
| std   | 1.29099 |
| min   | 0       |
| 25%   | 0.75    |
| 50%   | 1.5     |
| 75%   | 2.25    |
| max   | 3       |  

이 때 매개변수로 **include/exclude** 를 사용하여 출력결과를 조절할 수 있다.  

```Python  
>>> df.describe(include=['object'])
```  

|        | a   |
|:-------|:----|
| count  | 4   |
| unique | 2   |
| top    | No  |
| freq   | 2   |  

```Python  
>>> df.describe(include=['number'])
```  

|       |       b |
|:------|--------:|
| count | 4       |
| mean  | 1.5     |
| std   | 1.29099 |
| min   | 0       |
| 25%   | 0.75    |
| 50%   | 1.5     |
| 75%   | 2.25    |
| max   | 3       |  

```Python  
>>> df.describe(include='all')
```  

|        | a   |         b |
|:-------|:----|----------:|
| count  | 4   |   4       |
| unique | 2   | nan       |
| top    | No  | nan       |
| freq   | 2   | nan       |
| mean   | nan |   1.5     |
| std    | nan |   1.29099 |
| min    | nan |   0       |
| 25%    | nan |   0.75    |
| 50%    | nan |   1.5     |
| 75%    | nan |   2.25    |
| max    | nan |   3       |

### Index of min/max values  

**idxmin()** 과 **idxmax()** 함수는 시리즈와 데이터프레임의 인덱스 레이블의 최소값과 최댓값을 확인하는 기능을 한다.  

```Python  
>>> s1 = pd.Series(np.random.randn(5))  
>>> s1
```  

```
0    0.013833  
1    1.375255  
2   -0.261117  
3   -1.300798  
4    0.550127  
dtype: float64  
```  

```Python  
>>> s1.idxmin(), s1.idxmax()
```  

```
(3, 1)
```  

```Python  
>>> df1 = pd.DataFrame(np.random.randn(5, 3), columns=['A','B','C'])
```  

|    |          A |         B |         C |
|---:|-----------:|----------:|----------:|
|  0 | -0.307946  |  0.96568  |  0.854274 |
|  1 | -0.734701  | -0.763467 |  0.805104 |
|  2 |  0.0317531 |  0.494293 | -0.720657 |
|  3 |  2.08982   |  0.295745 |  1.1382   |
|  4 |  0.260457  |  0.785826 |  0.109045 |  

```Python  
>>> df1.idxmin(axis=0)
```  

```
A    1  
B    1  
C    2  
dtype: int64  
```  

```Python  
>>> df1.idxmax(axis=1)
```  

```
0    B  
1    C  
2    B  
3    A  
4    B  
dtype: object  
```  

만약 최솟값과 최댓값을 찾을 때 행 혹은 열이 중복값을 찾는다면 제일 먼저 찾은값을 찾는다.  

```Python  
>>> df3 = pd.DataFrame([2, 1, 1, 3, np.nan], columns=['A'], index=list('edcba'))  
>>> df3
```  

|    |   A |
|:---|----:|
| e  |   2 |
| d  |   1 |
| c  |   1 |
| b  |   3 |
| a  | nan |  

```Python  
>>> df3['A'].idxmin()
```  

```  
'd'
```  

### Value counts(histogrramming) / mode  

**value_counts()** 시리즈 메소드는 1차원의 배열을 막대형으로 나타내며 값의 갯수를 보여준다.  

```Python  
>>> data = np.random.randint(0, 7, size=50)  
>>> data
```  

```  
array([5, 3, 6, 1, 4, 1, 3, 0, 0, 3, 2, 4, 5, 3, 1, 4, 6, 2, 2, 1, 5, 6,  
       6, 0, 0, 4, 6, 5, 1, 4, 6, 3, 1, 3, 4, 6, 0, 4, 3, 6, 3, 6, 2, 2,  
       1, 2, 5, 3, 0, 4])
```  

```Python  
>>> s = pd.Series(data)  
>>> s.value_counts()
```  

```  
6    9  
3    9  
4    8  
1    7  
2    6  
0    6  
5    5  
dtype: int64  
```  

```Python  
>>> pd.value_counts(data)
```  

```  
6    9  
3    9  
4    8  
1    7  
2    6  
0    6  
5    5  
dtype: int64  
```  

또한 **mode()** 를 사용하여 시리즈 혹은 데이터프레임의 가장 빈번하게 발생하는 값들을 확인할 수 있다.  

```Python  
>>> s5 = pd.Series([1, 1, 3, 3, 3, 5, 5, 7, 7, 7])  
>>> s5.mode()
```  

```  
0    3  
1    7  
dtype: int64
```  

```Python  
>>> df5 = pd.DataFrame({"A": np.random.randint(0, 7, size=50),  
               "B": np.random.randint(-10, 15, size=50)})
>>> df5.mode()
```  

|    |   A |   B |
|---:|----:|----:|
|  0 |   1 |   3 |

### Descretization and quantiling  

연속적인 값인 이산화하기 위해 **cut(나눌 간격을 정수로 지정)** 과 **qcut(나눌 간격을 표본분위수로 지정)** 메소드를 사용한다.  

```Python  
>>> arr = np.random.randn(20)  
>>> arr
```

```
array([-0.99357841,  1.57974431, -0.60909831, -1.36768082, -0.7160791 ,  
       -0.02279333, -0.39298072, -1.45827772, -0.02566391,  0.92865122,  
        0.82623857,  1.41247274,  1.16325227,  0.92048371, -1.81958929,  
        0.73825483, -0.28654464,  1.06215868, -1.01476624,  0.31787862])  
```  

```Python  
>>> factor = pd.cut(arr, 4)  
>>> factor
```  

```  
[(-1.823, -0.97], (0.73, 1.58], (-0.97, -0.12], (-1.823, -0.97], (-0.97, -0.12], ..., (0.73, 1.58], (-0.97, -0.12], (0.73, 1.58], (-1.823, -0.97], (-0.12, 0.73]]
Length: 20
Categories (4, interval[float64]): [(-1.823, -0.97] < (-0.97, -0.12] < (-0.12, 0.73] < (0.73, 1.58]]
```  

```Python  
>>> factor = pd.cut(arr, [-5, -1, 0, 1, 5])  
>>> factor
```  

```  
[(-1, 0], (1, 5], (-1, 0], (-5, -1], (-1, 0], ..., (0, 1], (-1, 0], (1, 5], (-5, -1], (0, 1]]
Length: 20
Categories (4, interval[int64]): [(-5, -1] < (-1, 0] < (0, 1] < (1, 5]]
```  

```Python  
>>> arr = np.random.randn(30)  
>>> arr
```  

```  
array([ 1.15079381,  0.49939784, -0.15594853, -0.5517254 , -0.23522974,  
       -1.69728499, -0.80471605, -0.72416246,  0.79870411,  1.28311701,  
       -0.26005877,  0.4855533 ,  0.49194232, -1.89062664, -0.43397157,  
        0.77145788, -0.32865781,  0.36810471, -1.76766844, -0.74308291,  
       -0.05939578,  1.55420964, -0.82908721,  0.92783387,  0.55435694,  
        0.10418023,  0.3697685 , -0.39919188,  1.13068469, -0.15891597])  
```  

```Python  
>>> factor = pd.qcut(arr, [0, .25, .5, .75, 1])  
>>> factor
```  

```  
[(0.541, 1.554], (-0.108, 0.541], (-0.522, -0.108], (-1.892, -0.522], (-0.522, -0.108], ..., (-0.108, 0.541], (-0.108, 0.541], (-0.522, -0.108], (0.541, 1.554], (-0.522, -0.108]]
Length: 30
Categories (4, interval[float64]): [(-1.892, -0.522] < (-0.522, -0.108] < (-0.108, 0.541] < (0.541, 1.554]]
```  

```Python  
>>> pd.value_counts(factor)
```  

```  
(0.541, 1.554]      8  
(-1.892, -0.522]    8  
(-0.108, 0.541]     7  
(-0.522, -0.108]    7  
dtype: int64  
```  

무한을 기준으로 잘라낼 수도 있다.  

```Python  
>>> arr = np.random.randn(20)  
>>> factor = pd.cut(arr, [-np.inf, 0, np.inf])  
>>> factor
```  

```  
[(0.0, inf], (0.0, inf], (0.0, inf], (-inf, 0.0], (-inf, 0.0], ..., (-inf, 0.0], (0.0, inf], (0.0, inf], (0.0, inf], (-inf, 0.0]]
Length: 20
Categories (2, interval[float64]): [(-inf, 0.0] < (0.0, inf]]
```  

## 6.Function application  

아래 함수들의 사용 여부를 인지하여 데이터프레임과 시리즈를 적절하게 사용하게되면 판다스 오브젝트를 훨씬  
손 쉽게 사용할 수 있다.  

### Tablewise function application  

함수를 체인하여 사용해야할 경우 **.pipe()** 메소드를 사용하는것이 더 편리할 수 있다.  

먼저 메소드를 사용해보기위해 사용자정의 함수를 두 개와 임시 데이터프레임을 생성한다.  

```Python  
>>> def extract_city_name(df):  
     df['city_name'] = df['city_and_code'].str.split(",").str.get(0)  
     return df  

>>> def add_country_name(df, country_name = None):  
     col = 'city_name'  
     df['city_and_country'] = df[col] + country_name  
     return df  

>>> df_p = pd.DataFrame({'city_and_code' : ['Chicago, IL']})  
```  

먼저 일반적으로 사용하는 함수 연속사용이다.  

```Python  
>>> add_country_name(extract_city_name(df_p), country_name='US')
```  

|    | city_and_code   | city_name   | city_and_country   |
|---:|:----------------|:------------|:-------------------|
|  0 | Chicago, IL     | Chicago     | ChicagoUS          |  

이번에는 pipe() 메소드를 사용한 함수 체인이다.
```Python  
>>> (df_p.pipe(extract_city_name)  
        .pipe(add_country_name, country_name='US'))
```  

|    | city_and_code   | city_name   | city_and_country   |
|---:|:----------------|:------------|:-------------------|
|  0 | Chicago, IL     | Chicago     | ChicagoUS          |  

```  
두 방법이 동일하게 작동하는것을 확인할 수 있다.  
```  

### Row or column-wise function applicatioin  

**.apply()** 함수를 사용하여 데이터프레임의 축을 기준으로 통계적인 정보를 간략하게 확인할 수 있다.  

```Python   
>>> df['home_goals'].apply(np.mean)
```

```  
0       0.0  
1       3.0  
2       1.0  
3       0.0  
4       2.0  
       ...   
3663    4.0  
3664    0.0  
3665    2.0  
3666    3.0  
3667    0.0  
Name: home_goals, Length: 3668, dtype: float64
```  

또한 괄호안에 문자열을 사용할수도 있다.  

```Python  
>>> df.apply('mean')
```  

```  
home_goals    1.551799  
away_goals    1.198201  
dtype: float64  
```  

apply 메서드안에 추가 매개변수를 입력하여 더 구체적인 정보를 살펴볼 수 있다.  

```Python  
>>> tsdf = pd.DataFrame(np.random.randn(1000, 3), columns=['A','B','C'],
                   index=pd.date_range('1/1/2000', periods=1000))

>>> tsdf.apply(lambda x : x.idxmax())
```  

```  
A   2001-11-28  
B   2000-04-24  
C   2002-08-15  
dtype: datetime64[ns]  
```  

```Python  
>>> def subtract_and_divide(x, sub, divide = 1):
     return (x-sub) / divide

>>> tmp = tsdf.apply(subtract_and_divide, args=(5,), divide=3)
>>> print(tmp.to_markdown())
```  

|                     |         A |         B |         C |
|:--------------------|----------:|----------:|----------:|
| 2000-01-01 00:00:00 | -1.745    | -1.67402  | -1.93762  |
| 2000-01-02 00:00:00 | -1.85958  | -2.01404  | -1.34984  |
| 2000-01-03 00:00:00 | -1.34948  | -1.62634  | -1.2855   |
| 2000-01-04 00:00:00 | -1.8898   | -1.89961  | -1.82673  |
| 2000-01-05 00:00:00 | -0.839412 | -1.496    | -1.11361  |
| 2000-01-06 00:00:00 | -1.9484   | -1.62996  | -1.20595  |
| 2000-01-07 00:00:00 | -1.24549  | -1.12449  | -1.33754  |
| 2000-01-08 00:00:00 | -1.6188   | -1.83663  | -1.88883  |
| 2000-01-09 00:00:00 | -1.56541  | -1.88771  | -1.12292  |
| 2000-01-10 00:00:00 | -1.78074  | -1.80143  | -1.73056  |
| 2000-01-11 00:00:00 | -1.37461  | -1.61463  | -1.79432  |
| 2000-01-12 00:00:00 | -1.82991  | -1.59375  | -2.16066  |
| 2000-01-13 00:00:00 | -1.45812  | -1.41979  | -1.98306  |
| 2000-01-14 00:00:00 | -1.56264  | -1.48197  | -1.71941  |
| 2000-01-15 00:00:00 | -2.12301  | -1.8444   | -2.21301  |
| 2000-01-16 00:00:00 | -1.84389  | -1.62153  | -1.8379   |
| 2000-01-17 00:00:00 | -1.79762  | -1.85483  | -1.62741  |
| 2000-01-18 00:00:00 | -1.95687  | -1.73154  | -1.76231  |  
> 추가적으로 출력되는 부분은 생략하였다.  

행이나 열에 시리즈의 메서드를 적용할수도 있다.  

```Python  
>>> tsdf.apply(pd.Series.interpolate)
```  

|                     |            A |            B |           C |
|:--------------------|-------------:|-------------:|------------:|
| 2000-01-01 00:00:00 | -0.234998    | -0.0220618   | -0.812864   |
| 2000-01-02 00:00:00 | -0.578754    | -1.04212     |  0.950494   |
| 2000-01-03 00:00:00 |  0.951572    |  0.120993    |  1.14351    |
| 2000-01-04 00:00:00 | -0.669386    | -0.698823    | -0.48018    |
| 2000-01-05 00:00:00 |  2.48176     |  0.512006    |  1.65917    |
| 2000-01-06 00:00:00 | -0.845202    |  0.110124    |  1.38216    |
| 2000-01-07 00:00:00 |  1.26354     |  1.62652     |  0.987382   |
| 2000-01-08 00:00:00 |  0.143601    | -0.509895    | -0.666476   |
| 2000-01-09 00:00:00 |  0.303776    | -0.66313     |  1.63123    |
| 2000-01-10 00:00:00 | -0.342223    | -0.404277    | -0.191693   |
| 2000-01-11 00:00:00 |  0.876158    |  0.156111    | -0.382975   |
| 2000-01-12 00:00:00 | -0.489744    |  0.218755    | -1.48198    |
| 2000-01-13 00:00:00 |  0.625647    |  0.740618    | -0.94917    |
| 2000-01-14 00:00:00 |  0.312084    |  0.554088    | -0.15822    |
| 2000-01-15 00:00:00 | -1.36903     | -0.533213    | -1.63903    |
| 2000-01-16 00:00:00 | -0.531657    |  0.135399    | -0.513701   |
> 추가적으로 출력되는 부분은 생략하였다.  

마지막으로 apply 메서드는 **raw** 라는 매개변수를 가지고있다. 이것은 각 열 혹은 행이 시리즈 혹은 ndarray 객체로 전달될지의 여부를 결정한다.  
기본값은 False로, 이 때는 시리즈로 전달되며 True일 경우엔 ndarray로 전달되며 이 때가 더 나은 성능을 보여준다.  

### Aggregation API  

**.aggregate()** 혹은 **.agg()** 메소드는 엑셀에서의 집계함수와 비슷한 기능을 수행한다.  

```Python  
>>> tsdf = pd.DataFrame(np.random.randn(10, 3), columns=['A','B','C'],
                   index=pd.date_range('5/1/2020', periods=10))  
>>> tsdf
```  

|                     |         A |         B |         C |
|:--------------------|----------:|----------:|----------:|
| 2020-05-01 00:00:00 |  0.407908 | -0.600054 | -1.41581  |
| 2020-05-02 00:00:00 |  0.179237 | -0.734658 | -1.79698  |
| 2020-05-03 00:00:00 |  0.954097 | -0.882917 |  0.795765 |
| 2020-05-04 00:00:00 | -0.551622 |  1.74542  | -1.88462  |
| 2020-05-05 00:00:00 | -0.131639 |  1.14236  | -1.33374  |
| 2020-05-06 00:00:00 |  0.802303 |  0.441731 | -0.394808 |
| 2020-05-07 00:00:00 | -0.206431 | -1.32951  | -1.49405  |
| 2020-05-08 00:00:00 | -2.55758  |  0.367704 | -0.557975 |
| 2020-05-09 00:00:00 | -0.674054 |  1.63908  | -0.138926 |
| 2020-05-10 00:00:00 | -0.592699 |  0.668945 | -1.36891  |  

```Python  
>>> tsdf.iloc[3:7] = np.nan  
>>> tsdf
```  

|                     |          A |          B |          C |
|:--------------------|-----------:|-----------:|-----------:|
| 2020-05-01 00:00:00 |   0.407908 |  -0.600054 |  -1.41581  |
| 2020-05-02 00:00:00 |   0.179237 |  -0.734658 |  -1.79698  |
| 2020-05-03 00:00:00 |   0.954097 |  -0.882917 |   0.795765 |
| 2020-05-04 00:00:00 | nan        | nan        | nan        |
| 2020-05-05 00:00:00 | nan        | nan        | nan        |
| 2020-05-06 00:00:00 | nan        | nan        | nan        |
| 2020-05-07 00:00:00 | nan        | nan        | nan        |
| 2020-05-08 00:00:00 |  -2.55758  |   0.367704 |  -0.557975 |
| 2020-05-09 00:00:00 |  -0.674054 |   1.63908  |  -0.138926 |
| 2020-05-10 00:00:00 |  -0.592699 |   0.668945 |  -1.36891  |

단일 함수에 대해서 agg() 함수를 사용하면 apply() 함수와 동일한 기능을 수행한다. 마찬가지로 문자열로 매개변수를 지정할 수 있으며  
출력결과는 시리즈로 반환된다.  

```Python  
>>> tsdf.agg(np.sum)
```  
```  
A   -2.283095  
B    0.458099  
C   -4.482836  
dtype: float64  
```

```Python  
>>> tsdf.agg('sum')
```  

```  
A   -2.283095  
B    0.458099  
C   -4.482836  
dtype: float64  
```  

```Python  
>>> tsdf.sum()
```  

```
A   -2.283095  
B    0.458099  
C   -4.482836  
dtype: float64  
```  

단일 집계함수를 시리즈에 사용하면 상수 값을 반환한다.  

```Python  
>>> tsdf['A'].agg('sum')
```  

```  
-2.2830949400475666
```  

* 다중 집계함수

다중 집계함수는 리스트를 매개변수로 사용하며 결과는 데이터프레임의 행으로 반환된다.  

```Python   
>>> tsdf.agg(['sum'])
```  

|     |        A |        B |        C |
|:----|---------:|---------:|---------:|
| sum | -2.28309 | 0.458099 | -4.48284 |  

```Python  
>>> tsdf.agg(['sum','mean'])
```  

|      |         A |         B |         C |
|:-----|----------:|----------:|----------:|
| sum  | -2.28309  | 0.458099  | -4.48284  |
| mean | -0.380516 | 0.0763498 | -0.747139 |  

시리즈에서의 다중 집계함수는 시리즈를 반환한다.  

```Python  
>>> tsdf['A'].agg(['sum','mean'])
```  

```  
sum    -2.283095  
mean   -0.380516  
Name: A, dtype: float64
```  

lambda 함수를 사용하면 해당 결과의 행에 인덱스로 **<lambda>** 라고 나타난다.  

```Python  
>>> tsdf['A'].agg(['sum', lambda x: x.mean()])
```  

```  
sum        -2.283095  
<lambda>   -0.380516  
Name: A, dtype: float64
```  

사용자 지정 함수를 사용할 수 있으며 해당 결과의 행에 함수의 이름이 나타난다.  

```Python  
>>> def mymean(x):
>>>    return x.mean()

>>> tsdf['A'].agg(['sum',mymean])
```  

```
sum      -2.283095  
mymean   -0.380516  
Name: A, dtype: float64  
```  

* 딕셔너리 사용  

매개변수로 딕셔너리를 사용해 열에 대한 연산을 각각 수행하게 할 수 있다.  

```Python  
>>> tsdf.agg({'A': 'mean', 'B' : 'sum'})
```  

```  
A   -0.380516  
B    0.458099  
dtype: float64  
```  

딕셔너리 안에서 집계함수를 리스트로 지정하게 되면 데이터프레임으로 반환되는것을 알 수 있다.  

```Python  
>>> tsdf.agg({'A' : ['mean','min'], 'B' : 'sum'})
```  

|      |          A |          B |
|:-----|-----------:|-----------:|
| mean |  -0.380516 | nan        |
| min  |  -2.55758  | nan        |
| sum  | nan        |   0.458099 |  

* mixed types  

다양한 타입의 데이터에 집계함수를 사용하고자 한다면 오직 agg() 함수만이 원하는 결과를 반환할 수 있다.  

```Python  
>>> mdf = pd.DataFrame({'A' : [1, 2, 3],
                   'B' : [1., 2., 3.,],
                   'C' : ['foo', 'bar', 'baz'],
                   'D' : pd.date_range('20200501', periods=3)})
>>> mdf.dtypes
```  

```  
A             int64  
B           float64  
C            object  
D    datetime64[ns]  
dtype: object  
```  

```Python  
>>> mdf.agg(['min', 'sum'])
```  

|     |   A |   B | C         | D                   |
|:----|----:|----:|:----------|:--------------------|
| min |   1 |   1 | bar       | 2020-05-01 00:00:00 |
| sum |   6 |   6 | foobarbaz | NaT                 |  

* custom describe  

또한 집계함수는 describe 함수와 비슷한 기능을 하도록 사용자만의 describe 함수를 만들 수 있다.  

```Python  
>>> from functools import partial  
>>> q_25 = partial(pd.Series.quantile, q=0.25)  
>>> q_25.__name__ = '25%'  
>>> q_75 = partial(pd.Series.quantile, q=0.75)  
>>> q_75.__name__ = '75%'  
>>> tsdf.agg(['count','mean','std','min',q_25,'median',q_75,'max'])  
```  

|        |         A |          B |         C |
|:-------|----------:|-----------:|----------:|
| count  |  6        |  6         |  6        |
| mean   | -0.380516 |  0.0763498 | -0.747139 |
| std    |  1.23182  |  0.991325  |  0.971817 |
| min    | -2.55758  | -0.882917  | -1.79698  |
| 25%    | -0.653715 | -0.701007  | -1.40409  |
| median | -0.206731 | -0.116175  | -0.963444 |
| 75%    |  0.350741 |  0.593635  | -0.243689 |
| max    |  0.954097 |  1.63908   |  0.795765 |  

### Transform API  

**transform()** 메소드는 원본 객체와 같은 크기의 객체로 반환한다. 또한 다중 연산을 지원하기 때문에 agg() 메소드와 비슷한 역할을 한다.  

```Python  
>>> tsdf = pd.DataFrame(np.random.randn(10, 3), columns=['A','B','C'],
                   index=pd.date_range('20200501', periods=10))  
>>> tsdf.iloc[3:7] = np.nan  
>>> tsdf
```  

|                     |           A |            B |          C |
|:--------------------|------------:|-------------:|-----------:|
| 2020-05-01 00:00:00 |  -0.896244  |   0.682385   |   0.225629 |
| 2020-05-02 00:00:00 |  -0.97757   |  -2.09908    |   1.43179  |
| 2020-05-03 00:00:00 |   0.584787  |  -0.377973   |   0.425982 |
| 2020-05-04 00:00:00 | nan         | nan          | nan        |
| 2020-05-05 00:00:00 | nan         | nan          | nan        |
| 2020-05-06 00:00:00 | nan         | nan          | nan        |
| 2020-05-07 00:00:00 | nan         | nan          | nan        |
| 2020-05-08 00:00:00 |  -0.744223  |   0.982502   |   0.649855 |
| 2020-05-09 00:00:00 |   0.439956  |  -0.00475368 |   0.88607  |
| 2020-05-10 00:00:00 |   0.0178599 |  -0.118774   |  -0.640164 |  

transform 메소드에는 넘파이 함수나 문자열, 사용자 지정 함수를 입력할 수 있다.  

```Python  
>>> tsdf.transform(np.abs)
```  

|                     |           A |            B |          C |
|:--------------------|------------:|-------------:|-----------:|
| 2020-05-01 00:00:00 |   0.896244  |   0.682385   |   0.225629 |
| 2020-05-02 00:00:00 |   0.97757   |   2.09908    |   1.43179  |
| 2020-05-03 00:00:00 |   0.584787  |   0.377973   |   0.425982 |
| 2020-05-04 00:00:00 | nan         | nan          | nan        |
| 2020-05-05 00:00:00 | nan         | nan          | nan        |
| 2020-05-06 00:00:00 | nan         | nan          | nan        |
| 2020-05-07 00:00:00 | nan         | nan          | nan        |
| 2020-05-08 00:00:00 |   0.744223  |   0.982502   |   0.649855 |
| 2020-05-09 00:00:00 |   0.439956  |   0.00475368 |   0.88607  |
| 2020-05-10 00:00:00 |   0.0178599 |   0.118774   |   0.640164 |  

```Python  
>>> tsdf.transform('abs')
```   

|                     |           A |            B |          C |
|:--------------------|------------:|-------------:|-----------:|
| 2020-05-01 00:00:00 |   0.896244  |   0.682385   |   0.225629 |
| 2020-05-02 00:00:00 |   0.97757   |   2.09908    |   1.43179  |
| 2020-05-03 00:00:00 |   0.584787  |   0.377973   |   0.425982 |
| 2020-05-04 00:00:00 | nan         | nan          | nan        |
| 2020-05-05 00:00:00 | nan         | nan          | nan        |
| 2020-05-06 00:00:00 | nan         | nan          | nan        |
| 2020-05-07 00:00:00 | nan         | nan          | nan        |
| 2020-05-08 00:00:00 |   0.744223  |   0.982502   |   0.649855 |
| 2020-05-09 00:00:00 |   0.439956  |   0.00475368 |   0.88607  |
| 2020-05-10 00:00:00 |   0.0178599 |   0.118774   |   0.640164 |   

```Python  
>>> tsdf.transform(lambda x : x.abs())
```   

|                     |           A |            B |          C |
|:--------------------|------------:|-------------:|-----------:|
| 2020-05-01 00:00:00 |   0.896244  |   0.682385   |   0.225629 |
| 2020-05-02 00:00:00 |   0.97757   |   2.09908    |   1.43179  |
| 2020-05-03 00:00:00 |   0.584787  |   0.377973   |   0.425982 |
| 2020-05-04 00:00:00 | nan         | nan          | nan        |
| 2020-05-05 00:00:00 | nan         | nan          | nan        |
| 2020-05-06 00:00:00 | nan         | nan          | nan        |
| 2020-05-07 00:00:00 | nan         | nan          | nan        |
| 2020-05-08 00:00:00 |   0.744223  |   0.982502   |   0.649855 |
| 2020-05-09 00:00:00 |   0.439956  |   0.00475368 |   0.88607  |
| 2020-05-10 00:00:00 |   0.0178599 |   0.118774   |   0.640164 |  

transform() 메소드가 단일 함수와 동일한 기능을 수행할 수 있는것을 확인할 수 있다.  

```Python  
>>> np.abs(tsdf)
```  

|                     |           A |            B |          C |
|:--------------------|------------:|-------------:|-----------:|
| 2020-05-01 00:00:00 |   0.896244  |   0.682385   |   0.225629 |
| 2020-05-02 00:00:00 |   0.97757   |   2.09908    |   1.43179  |
| 2020-05-03 00:00:00 |   0.584787  |   0.377973   |   0.425982 |
| 2020-05-04 00:00:00 | nan         | nan          | nan        |
| 2020-05-05 00:00:00 | nan         | nan          | nan        |
| 2020-05-06 00:00:00 | nan         | nan          | nan        |
| 2020-05-07 00:00:00 | nan         | nan          | nan        |
| 2020-05-08 00:00:00 |   0.744223  |   0.982502   |   0.649855 |
| 2020-05-09 00:00:00 |   0.439956  |   0.00475368 |   0.88607  |
| 2020-05-10 00:00:00 |   0.0178599 |   0.118774   |   0.640164 |  

시리즈를 transform하면 반환되는 객체도 시리즈로 반환된다.  

```Python  
>>> tsdf['A'].transform(np.abs)
```  

```  
2020-05-01    0.896244  
2020-05-02    0.977570  
2020-05-03    0.584787  
2020-05-04         NaN  
2020-05-05         NaN  
2020-05-06         NaN  
2020-05-07         NaN  
2020-05-08    0.744223  
2020-05-09    0.439956  
2020-05-10    0.017860  
Freq: D, Name: A, dtype: float64
```  

#### Transform with multiple functions  

다중 함수를 사용하면 멀티인덱스를 가지는 데이터프레임을 반환하며, 제일 상단부엔 원래 가지고있던 열의 레이블을, 아래엔 transform() 메소드에  
적용한 레이블이 나타난다.  

```Python   
>>> tsdf.transform([np.abs, lambda x : x + 1])
```  

|                     |   ('A', 'absolute') |   ('A', '<lambda>') |   ('B', 'absolute') |   ('B', '<lambda>') |   ('C', 'absolute') |   ('C', '<lambda>') |
|:--------------------|--------------------:|--------------------:|--------------------:|--------------------:|--------------------:|--------------------:|
| 2020-05-01 00:00:00 |           0.896244  |           0.103756  |          0.682385   |            1.68238  |            0.225629 |            1.22563  |
| 2020-05-02 00:00:00 |           0.97757   |           0.0224299 |          2.09908    |           -1.09908  |            1.43179  |            2.43179  |
| 2020-05-03 00:00:00 |           0.584787  |           1.58479   |          0.377973   |            0.622027 |            0.425982 |            1.42598  |
| 2020-05-04 00:00:00 |         nan         |         nan         |        nan          |          nan        |          nan        |          nan        |
| 2020-05-05 00:00:00 |         nan         |         nan         |        nan          |          nan        |          nan        |          nan        |
| 2020-05-06 00:00:00 |         nan         |         nan         |        nan          |          nan        |          nan        |          nan        |
| 2020-05-07 00:00:00 |         nan         |         nan         |        nan          |          nan        |          nan        |          nan        |
| 2020-05-08 00:00:00 |           0.744223  |           0.255777  |          0.982502   |            1.9825   |            0.649855 |            1.64986  |
| 2020-05-09 00:00:00 |           0.439956  |           1.43996   |          0.00475368 |            0.995246 |            0.88607  |            1.88607  |
| 2020-05-10 00:00:00 |           0.0178599 |           1.01786   |          0.118774   |            0.881226 |            0.640164 |            0.359836 |  

시리즈에 다중 함수를 사용하게되면 데이터프레임을 반환하게 된다.  

```Python  
>>> tsdf['A'].transform([np.abs, lambda x : x + 1])
```  

|                     |    absolute |    <lambda> |
|:--------------------|------------:|------------:|
| 2020-05-01 00:00:00 |   0.896244  |   0.103756  |
| 2020-05-02 00:00:00 |   0.97757   |   0.0224299 |
| 2020-05-03 00:00:00 |   0.584787  |   1.58479   |
| 2020-05-04 00:00:00 | nan         | nan         |
| 2020-05-05 00:00:00 | nan         | nan         |
| 2020-05-06 00:00:00 | nan         | nan         |
| 2020-05-07 00:00:00 | nan         | nan         |
| 2020-05-08 00:00:00 |   0.744223  |   0.255777  |
| 2020-05-09 00:00:00 |   0.439956  |   1.43996   |
| 2020-05-10 00:00:00 |   0.0178599 |   1.01786   |  


#### Transforming with a dict  

함수를 딕셔너리 형태로 입력하여 각 열에 선택적으로 연산을 수행하도록 할 수 있다.  

```Python  
>>> tsdf.transform({'A' : np.abs, 'B' : lambda x : x + 1})
```  

|                     |           A |          B |
|:--------------------|------------:|-----------:|
| 2020-05-01 00:00:00 |   0.896244  |   1.68238  |
| 2020-05-02 00:00:00 |   0.97757   |  -1.09908  |
| 2020-05-03 00:00:00 |   0.584787  |   0.622027 |
| 2020-05-04 00:00:00 | nan         | nan        |
| 2020-05-05 00:00:00 | nan         | nan        |
| 2020-05-06 00:00:00 | nan         | nan        |
| 2020-05-07 00:00:00 | nan         | nan        |
| 2020-05-08 00:00:00 |   0.744223  |   1.9825   |
| 2020-05-09 00:00:00 |   0.439956  |   0.995246 |
| 2020-05-10 00:00:00 |   0.0178599 |   0.881226 |  

딕셔너리 안에 리스트를 넣어 멀티인덱스를 가지는 데이터프레임을 생성할 수 있다.  

```Python  
>>> tsdf.transform({'A' : np.abs, 'B' : [lambda x : x + 1, 'sqrt']})
```  

|                     |   ('A', 'absolute') |   ('B', '<lambda>') |   ('B', 'sqrt') |
|:--------------------|--------------------:|--------------------:|----------------:|
| 2020-05-01 00:00:00 |           0.896244  |            1.68238  |        0.826066 |
| 2020-05-02 00:00:00 |           0.97757   |           -1.09908  |      nan        |
| 2020-05-03 00:00:00 |           0.584787  |            0.622027 |      nan        |
| 2020-05-04 00:00:00 |         nan         |          nan        |      nan        |
| 2020-05-05 00:00:00 |         nan         |          nan        |      nan        |
| 2020-05-06 00:00:00 |         nan         |          nan        |      nan        |
| 2020-05-07 00:00:00 |         nan         |          nan        |      nan        |
| 2020-05-08 00:00:00 |           0.744223  |            1.9825   |        0.991212 |
| 2020-05-09 00:00:00 |           0.439956  |            0.995246 |      nan        |
| 2020-05-10 00:00:00 |           0.0178599 |            0.881226 |      nan        |  

### Applying elementwise functions  

모든 함수가 벡터화를 허용하지 않기 때문에(넘파이 배열은 벡터화를 수용하며 또다른 배열이나 값으로 반환한다) 데이터프레임에서는 **applymap()** 메소드를 시리즈에서는 **map()** 을 사용하여 파이썬 함수가 단일값을 가지고 이것을 반환하도록 할 수 있다.  

```Python  
>>> df4 = pd.DataFrame(np.random.randn(4,3), columns=['one','two','three'],
                  index=['a','b','c','d'])  
>>> df4['one']['d'] = np.nan  
>>> df4['three']['a'] = np.nan  
>>> df4
```  

|    |        one |       two |      three |
|:---|-----------:|----------:|-----------:|
| a  |  -0.245643 | -2.0549   | nan        |
| b  |   0.22655  |  1.48683  |  -0.150279 |
| c  |  -0.530094 |  0.254373 |  -1.08476  |
| d  | nan        |  1.168    |   0.854002 |  

```Python  
>>> def f(x):  
>>>    return len(str(x))  

>>> df4['one'].map(f)
```  

```  
a    19  
b    19  
c    19  
d     3  
Name: one, dtype: int64
```  

```Python  
>>> df4.applymap(f)
```  

|    |   one |   two |   three |
|:---|------:|------:|--------:|
| a  |    19 |    19 |       3 |
| b  |    19 |    18 |      19 |
| c  |    19 |    19 |      19 |
| d  |     3 |    18 |      17 |  

**Series.map()** 이 가지는 특징 중 하나는 또 다른 시리즈 객체를 불러와 연산을 수행할 수 있다는 것이다.  
이것은 일종의 병합기능으로 볼 수 있다.  

```Python  
>>> s = pd.Series(['six','seven','six','seven','six'],
                index = ['a','b','c','d','e'])  
>>> t = pd.Series({'six' : 6., 'seven' : 7.})  
```  

```Python  
>>> s  
```  

```  
a      six  
b    seven  
c      six  
d    seven  
e      six  
dtype: object    
```  

```Python  
>>> t
```  

```  
six      6.0  
seven    7.0  
dtype: float64  
```  

```Python  
>>> s.map(t)
```  

```  
a    6.0  
b    7.0  
c    6.0  
d    7.0  
e    6.0  
dtype: float64  
```  

## 7. Reindexing and altering labels  

**reindex()** 함수는 기존 인덱스를 지정한 새로운 인덱스로 변경하는 기능을 한다. reindex의 의미는 데이터를 확인하여 주어진 레이블과 매칭시키는것을 뜻하며   
아래와 같은 것들을 할 수 있게된다.  

* 기존 데이터의 순서를 새 레이블 집합과 일치하도록 변경  
* 기존에 존재하지 않는 레이블을 지정할 경우, 해당값은 누락값이된다.    
* 지정될 경우, 로직을 사용하여 누락된 레이블에 대한 데이터를 채운다(시계열 데이터 작업에 유용)  

```Python  
>>> s = pd.Series(np.random.randn(5), index=['a','b','c','d','e'])
>>> s
```  

```  
a   -0.175884  
b   -0.714753  
c    0.255026  
d   -0.150072  
e    1.262673  
dtype: float64  
```  

```Python  
>>> s.reindex(['e','b','f','d'])
```  

```  
e    1.262673  
b   -0.714753  
f         NaN  
d   -0.150072  
dtype: float64  
```  

> f는 기존에 존재하지 않았던 레이블이기 때문에 누락값이 할당되는것을 확인할 수 있다.  

데이터프레임에서 reindex는 행과 열을 지정할 수 있다.  

```Python  
>>> df = pd.DataFrame(np.random.randn(4, 3), index=['a','b','c','d'], columns=['one','two','three'])
>>> df
```  

|    |       one |       two |     three |  
|:---|----------:|----------:|----------:|  
| a  |  1.17957  |  1.08527  |  0.806466 |  
| b  |  1.50887  |  1.4767   | -1.4075   |  
| c  | -2.08019  |  1.88112  | -1.08034  |  
| d  |  0.452879 | -0.640094 | -0.39275  |  

```Python  
>>> df.reindex(index=['c','f','b'], columns=['three','two','one'])
```  

|    |     three |       two |       one |
|:---|----------:|----------:|----------:|
| c  |  -1.08034 |   1.88112 |  -2.08019 |
| f  | nan       | nan       | nan       |
| b  |  -1.4075  |   1.4767  |   1.50887 |  

또한 축을 설정하여 지정한 인덱스로 변경할 수 있다.  

```Python  
>>> df.reindex(['c','f','b'], axis='index')
```  

|    |       one |       two |     three |
|:---|----------:|----------:|----------:|
| c  |  -2.08019 |   1.88112 |  -1.08034 |
| f  | nan       | nan       | nan       |
| b  |   1.50887 |   1.4767  |  -1.4075  |  

index 객체는 실제 축의 레이블을 가지기 때문에 객체간 공유가 가능하다.  

```Python  
>>> rs = s.reindex(df.index)  
>>> rs
```  

```  
a   -0.175884  
b   -0.714753  
c    0.255026  
d   -0.150072  
dtype: float64  
```  

```Python  
>>> rs.index is df.index
```  

```   
True
```  
> 이는 reindex한 시리즈의 인덱스가 데이터프레임의 인덱스와 동일함을 의미한다.  

또한 데이터프레임의 reindex에서 축을 지정할때 'index'같은 문자열로 행과 열의 레이블을 단일로 지정할 수 있다.  

```Python  
>>> df.reindex(['c','f','b'], axis='index')
```  

|    |       one |       two |     three |
|:---|----------:|----------:|----------:|
| c  |  -2.08019 |   1.88112 |  -1.08034 |
| f  | nan       | nan       | nan       |
| b  |   1.50887 |   1.4767  |  -1.4075  |  

```Python  
>>> df.reindex(['three','two','one'], axis='columns')
```  

|    |     three |       two |       one |
|:---|----------:|----------:|----------:|
| a  |  0.806466 |  1.08527  |  1.17957  |
| b  | -1.4075   |  1.4767   |  1.50887  |
| c  | -1.08034  |  1.88112  | -2.08019  |
| d  | -0.39275  | -0.640094 |  0.452879 |  

### Reindexing to align with another object  

**reindex_like()** 함수는 하나의 객체를 가지고 있을때 또 다른 객체를 읽어들여 읽어낸 객체와 동일한 레이블과 해당 값을 출력한다.  

```Python  
>>> df2 = pd.DataFrame(np.random.randn(3,2), index=['a','b','c'], columns=['one','two'])  
>>> df2
```

|    |       one |       two |
|:---|----------:|----------:|
| a  | -0.954435 | -0.136404 |
| b  |  0.664582 | -0.745416 |
| c  | -0.582238 | -0.684242 |  

```Python  
>>> df
```  

|    |      one |        two |     three |
|:---|---------:|-----------:|----------:|
| a  | 1.08289  |  1.73894   | -0.168816 |
| b  | 1.5553   |  0.662961  |  1.29429  |
| c  | 1.79224  | -0.0619129 |  0.251609 |
| d  | 0.993658 |  0.66325   | -1.41489  |  

```Python  
>>> df.reindex_like(df2)
```  

|    |     one |        two |
|:---|--------:|-----------:|
| a  | 1.08289 |  1.73894   |
| b  | 1.5553  |  0.662961  |
| c  | 1.79224 | -0.0619129 |

### Aligning objects with each other with align  

**align()** 함수는 동시에 두 객체를 할당하는 가장 빠른 방법이다. 또한 **join** 매개변수를 지원한다.  

* join='outer' : 디폴트값으로, 단순하게 두 객체를 연결한다.  
* join='left' : 사용하는 객체를 기준으로 join한다.  
* join='right' : 대상으로 하는 객체를 기준으로 join한다.  
* join='inner' : 두 객체가 가지는 동일한 레이블을 기준으로 join한다.  

```Python  
>>> s = pd.Series(np.random.randn(5), index=['a', 'b', 'c', 'd', 'e'])  
>>> s1 = s[:4]  
>>> s2 = s[1:]
```  

```Python  
>>> s1
```  

```  
a    0.399127  
b    0.822136  
c    0.382556  
d   -0.481126  
dtype: float64  
```  

```Python  
>>> s2
```  

```  
b    0.822136  
c    0.382556  
d   -0.481126  
e   -0.252125  
dtype: float64  
```  

```Python  
>>> s1.align(s2, join='outer')
```  

```  
(a    0.399127  
 b    0.822136  
 c    0.382556  
 d   -0.481126  
 e         NaN  
 dtype: float64,  
 a         NaN  
 b    0.822136  
 c    0.382556  
 d   -0.481126  
 e   -0.252125  
 dtype: float64)    
```  

```Python  
>>> s1.align(s2, join='left')
```  

```  
(a    0.399127  
 b    0.822136  
 c    0.382556  
 d   -0.481126  
 dtype: float64,  
 a         NaN  
 b    0.822136  
 c    0.382556  
 d   -0.481126  
 dtype: float64)  
```  

```Python  
>>> s1.align(s2, join='right')
```  

```  
(b    0.822136  
 c    0.382556  
 d   -0.481126  
 e         NaN  
 dtype: float64,  
 b    0.822136  
 c    0.382556  
 d   -0.481126  
 e   -0.252125  
 dtype: float64)  
```  

```Python  
>>> s1.align(s2, join='inner')
```  

```  
(b    0.822136  
 c    0.382556  
 d   -0.481126  
 dtype: float64,  
 b    0.822136  
 c    0.382556  
 d   -0.481126  
 dtype: float64)  
```  

데이터프레임에서 join은 기본값으로 열과 행을 동시에 적용한다.  

```Python  
>>> df.align(df2, join='inner')
```  

```  
(        one       two  
 a  1.082888  1.738943  
 b  1.555301  0.662961  
 c  1.792241 -0.061913,  
         one       two  
 a -0.954435 -0.136404  
 b  0.664582 -0.745416  
 c -0.582238 -0.684242)  
```  

축을 지정하여 행 혹은 열만을 처리할 수도 있다.  

```Python  
>>> df.align(df2, join='inner', axis=0)
```  

```  
(        one       two     three  
 a  1.082888  1.738943 -0.168816  
 b  1.555301  0.662961  1.294289  
 c  1.792241 -0.061913  0.251609,   
         one       two  
 a -0.954435 -0.136404  
 b  0.664582 -0.745416  
 c -0.582238 -0.684242)  
```  

데이터프레임의 align에 시리즈를 할당하고자 한다면 axis 매개변수를 사용해 축 혹은 열을 지정해줘야한다.  

```Python  
>>> df.align(df2.iloc[0], axis=1)
```  

```  
(        one     three       two  
 a  1.082888 -0.168816  1.738943  
 b  1.555301  1.294289  0.662961  
 c  1.792241  0.251609 -0.061913  
 d  0.993658 -1.414891  0.663250,  
 one     -0.954435  
 three         NaN  
 two     -0.136404  
 Name: a, dtype: float64)  
```  

### Filling while reindexing  

reindex() 메소드는 선택적 파라미터 **method** 를 이용해 다양한 방법으로 값을 채울 수 있다  

| Method | Action  
|:-------|:------  
pad/ffill|앞에서부터 값을 채움  
bfill/backfill|뒤에서부터 값을 채움  
nearest |가장 인접한 인덱스값에서부터 값을 채움  

```Python  
>>> rng = pd.date_range('5/20/2020', periods=8)  
>>> rng
```  

```  
DatetimeIndex(['2020-05-20', '2020-05-21', '2020-05-22', '2020-05-23',  
               '2020-05-24', '2020-05-25', '2020-05-26', '2020-05-27'],  
              dtype='datetime64[ns]', freq='D')  
```  

```Python  
>>> ts = pd.Series(np.random.randn(8), index=rng)  
>>> ts  
```  

```  
2020-05-20   -0.505216  
2020-05-21   -0.817539  
2020-05-22    0.369850  
2020-05-23    0.495342  
2020-05-24    0.532168  
2020-05-25   -0.980164  
2020-05-26   -0.630167  
2020-05-27   -0.244960  
Freq: D, dtype: float64  
```  

```Python  
>>> ts2 = ts[[0, 3, 6]]  
>>> ts2
```  

```  
2020-05-20   -0.505216  
2020-05-23    0.495342  
2020-05-26   -0.630167  
dtype: float64  
```  

```Python  
>>> ts2.reindex(ts.index)
```  

```  
2020-05-20   -0.505216  
2020-05-21         NaN  
2020-05-22         NaN  
2020-05-23    0.495342  
2020-05-24         NaN  
2020-05-25         NaN  
2020-05-26   -0.630167  
2020-05-27         NaN  
Freq: D, dtype: float64  
```  

```Python  
>>> ts2.reindex(ts.index, method='ffill')
```  

```  
2020-05-20   -0.505216  
2020-05-21   -0.505216  
2020-05-22   -0.505216  
2020-05-23    0.495342  
2020-05-24    0.495342  
2020-05-25    0.495342  
2020-05-26   -0.630167  
2020-05-27   -0.630167  
Freq: D, dtype: float64  
```  

```Python  
>>> ts2.reindex(ts.index, method='bfill')
```  

```  
2020-05-20   -0.505216  
2020-05-21    0.495342  
2020-05-22    0.495342  
2020-05-23    0.495342  
2020-05-24   -0.630167  
2020-05-25   -0.630167  
2020-05-26   -0.630167  
2020-05-27         NaN  
Freq: D, dtype: float64  
```  

```Python  
>>> ts2.reindex(ts.index, method='nearest')
```  

```  
2020-05-20   -0.505216  
2020-05-21   -0.505216  
2020-05-22    0.495342  
2020-05-23    0.495342  
2020-05-24    0.495342  
2020-05-25   -0.630167  
2020-05-26   -0.630167  
2020-05-27   -0.630167  
Freq: D, dtype: float64  
```  
> 위 메소드들은 인덱스를 오름차순 혹은 내림차순으로 나열한다.  

nearest를 제외한 method 방식들은 모두 fillna/interpolate 함수를 사용한 결과가 동일한다.  

```Python   
>>> ts2.reindex(ts.index).fillna(method='ffill')
```  

```  
2020-05-20   -0.505216  
2020-05-21   -0.505216  
2020-05-22   -0.505216  
2020-05-23    0.495342  
2020-05-24    0.495342  
2020-05-25    0.495342  
2020-05-26   -0.630167   
2020-05-27   -0.630167   
Freq: D, dtype: float64  
```  
> 그러나 이 방식은 인덱스가 증가나 감소를하는 형식이 아니라면 ValueError를 일으킨다.

### Limits on filling while reindexing  

**limit** 과 **tolerance** 매개변수는 reindexing을 통해 값을 채우는 동안에 추가적인 조정을 할 수 있다.  
limit은 연속으로 대응하는 횟수를 제안한다.  

```Python  
>>> ts2.reindex(ts.index, method='ffill', limit=1)
```  

```  
2020-05-20   -0.505216  
2020-05-21   -0.505216  
2020-05-22   -0.505216  
2020-05-23    0.495342  
2020-05-24    0.495342  
2020-05-25    0.495342  
2020-05-26   -0.630167  
2020-05-27   -0.630167  
Freq: D, dtype: float64  
```  

반대로 tolerance는 인덱스 사이의 거리의 최대치를 결정한다.  

```Python  
>>> ts2.reindex(ts.index, method='ffill', tolerance='1 day')
```  

```  
2020-05-20   -0.505216  
2020-05-21   -0.505216  
2020-05-22         NaN  
2020-05-23    0.495342  
2020-05-24    0.495342  
2020-05-25         NaN  
2020-05-26   -0.630167  
2020-05-27   -0.630167  
Freq: D, dtype: float64  
```  

### Dropping labels from an axis  

reindex와 가장 밀접해있는 함수는 **drop** 이다. drop은 축으로부터 레이블들을 제거한다.  

```Python  
>>> df.drop(['a','d'], axis=0)
```  

|    |     one |        two |    three |
|:---|--------:|-----------:|---------:|
| b  | 1.5553  |  0.662961  | 1.29429  |
| c  | 1.79224 | -0.0619129 | 0.251609 |   

```Python  
>>> df.drop(['one'], axis=1)
```  

|    |        two |     three |
|:---|-----------:|----------:|
| a  |  1.73894   | -0.168816 |
| b  |  0.662961  |  1.29429  |
| c  | -0.0619129 |  0.251609 |
| d  |  0.66325   | -1.41489  |  

덜 명확한 방법이긴 하지만 reindex로 위와 같은 기능을 수행할 수 있다.  

```Python  
>>> df.reindex(df.index.difference(['a','d']))
```  

|    |     one |        two |    three |
|:---|--------:|-----------:|---------:|
| b  | 1.5553  |  0.662961  | 1.29429  |
| c  | 1.79224 | -0.0619129 | 0.251609 |  

### Renaming / mapping labels  

rename() 함수는 축의 레이블을 다시 설정할 수 있으며 이는 딕셔너리나 시리즈 혹은 임의의 함수를 기반으로 한다.  

```Python  
>>> s = pd.Series(np.random.randn(5), index=['a', 'b', 'c', 'd', 'e'])  
>>> s
```  

```  
a   -0.075894  
b    0.185599  
c   -0.519371  
d   -0.146455  
e    1.248039  
dtype: float64  
```

```Python  
>>> s.rename(str.upper)
```  

```  
A   -0.075894  
B    0.185599  
C   -0.519371  
D   -0.146455  
E    1.248039  
dtype: float64  
```  

만약 함수를 사용한다면 호출한 레이블의 값을 반환하며 딕셔너리나 시리즈에서도 사용할 수 있다.  

```Python  
>>> df = pd.DataFrame(np.random.randn(4, 3), index=['a','b','c','d'], columns=['one','two','three'])  
>>> df
```  

|    |        one |       two |     three |
|:---|-----------:|----------:|----------:|
| a  |  0.46764   | -0.762784 | -0.294786 |
| b  |  0.0442426 |  1.311    |  1.23261  |
| c  | -0.0144119 | -0.239189 |  0.708016 |
| d  | -0.430634  | -0.435274 | -0.342011 |  

```Python  
>>> df.rename(columns={'one':'foo','two':'bar'},
         index={'a':'apple','b':'banana','d':'durian'})  
```  

|        |        foo |       bar |     three |
|:-------|-----------:|----------:|----------:|
| apple  |  0.46764   | -0.762784 | -0.294786 |
| banana |  0.0442426 |  1.311    |  1.23261  |
| c      | -0.0144119 | -0.239189 |  0.708016 |
| durian | -0.430634  | -0.435274 | -0.342011 |  
​  
> 만약 매핑에서 행과 열의 레이블을 포함하지 않았다고 하더라도 에러를 출력하지는 않는다  

**DataFrame.rename()** 은 axis-style(축을 지정할 때 문자열로 지정하는것)을 지원한다.  
이 때는 단일 매핑(하나의 축만을 매핑하는것)을 사용할 때 유용하다.  

```Python  
>>> df.rename({'one':'foo','two':'bar'}, axis='columns')
```  

|    |        foo |       bar |     three |
|:---|-----------:|----------:|----------:|
| a  |  0.46764   | -0.762784 | -0.294786 |
| b  |  0.0442426 |  1.311    |  1.23261  |
| c  | -0.0144119 | -0.239189 |  0.708016 |
| d  | -0.430634  | -0.435274 | -0.342011 |  

```Python  
>>> df.rename({'a':'apple','b':'banana','d':'durian'})
```  

|        |        one |       two |     three |
|:-------|-----------:|----------:|----------:|
| apple  |  0.46764   | -0.762784 | -0.294786 |
| banana |  0.0442426 |  1.311    |  1.23261  |
| c      | -0.0144119 | -0.239189 |  0.708016 |
| durian | -0.430634  | -0.435274 | -0.342011 |  

rename 함수는 **inplace** 매개변수를 지원하며 기본값은 False지만 True로 지정하게되면 내재된 데이터의 정보가 변경된다.  

시리즈에서 rename은 스칼라나 리스트를 사용할 수 있다.  

```Python  
>>> s.rename('scalar-name')
```  

```  
a   -0.075894  
b    0.185599  
c   -0.519371  
d   -0.146455  
e    1.248039  
Name: scalar-name, dtype: float64  
```  

**rename_axis()** 함수는 멀티인덱스의 특정 이름을 변경할 때 사용한다.  

```Python  
>>> df = pd.DataFrame({'x':[1, 2, 3, 4, 5, 6 ],  
                  'y' :[10, 20, 30, 40, 50, 60]},  
                 index = pd.MultiIndex.from_product([['a','b','c'], [1,2]], names=['let','num']))  
>>> df
```  

<img width="147" alt="1" src="https://user-images.githubusercontent.com/43739827/83251525-ae78f700-a1e4-11ea-8996-488f4f65d9c5.png"></img>  

```Python  
>>> df.rename_axis(index={'let':'abc'})
```  

<img width="138" alt="2" src="https://user-images.githubusercontent.com/43739827/83251531-b0db5100-a1e4-11ea-98a0-69401892ac67.png"></img>  

```Python   
>>> df.rename_axis(index=str.upper)
```  

<img width="154" alt="3" src="https://user-images.githubusercontent.com/43739827/83251517-ab7e0680-a1e4-11ea-9631-c75e2dcf3de3.png"></img>  

##  8.Iteration  

판다스 객체에서의 반복은 객체의 유형에 의존한다. 시리즈에서 반복을 하게되면 리스트 형태로 반복하게되고 데이터프레임에서 반복을 하게되면  
딕셔너리 형태로써 키를 반복하게된다.  

간단하게 나타낸다면 for i in object를 했을때에  
```  
Series : value  
DataFrame : 열의 레이블
```  

```Python  
>>> df = pd.DataFrame({'col1' : np.random.randn(3),  
                  'col2' : np.random.randn(3)}, index=list('abc'))  
>>> df
```  

|    |      col1 |     col2 |
|:---|----------:|---------:|
| a  | -0.428519 | 0.756701 |
| b  |  0.359407 | 1.45551  |
| c  |  0.796692 | 2.11757  |  

```Python  
>>> for col in df:  
>>>     print(col)
```  

```   
col1
col2
```  

판다스 객체는  **items()** 함수를 사용할 수 있으며 이 함수를 사용하여 키와 밸류를 사용한 반복을 시행할 수 있다.  

데이터프레임에서 행의 레이블을 사용해 반복하고자 한다면 아래의 함수를 사용한다.  

```  
* iterrows() : 데이터프레임의 행을 인덱스, 시리즈쌍으로하여 반복한다. 이 때의 반환결과는 시리즈가된다.  
* itertuples() : 데이터프레임의 행을 이름이새겨진 튜플의 값으로하여 반복하며 iterrows()보다 더 빠르게 연산하기 때문에  
데이터프레임의 값에대한 반복을할때 더 선호되는 함수이다.
```  
